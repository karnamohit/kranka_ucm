{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/karnamohit/kranka_ucm/blob/master/tf1_test_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rtgEx4iIVXly"
   },
   "source": [
    "Importing all the useful libraries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G_vn7WnlmKCd"
   },
   "outputs": [],
   "source": [
    "#%tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "zGuZTN4AhVKa",
    "outputId": "1a3a06e4-f65f-487c-de00-f825a8229cba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jYKUs0zghlEf"
   },
   "outputs": [],
   "source": [
    "#!ls /content/drive/My\\ Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P8knKLFRVFvY"
   },
   "source": [
    "Checking the version of TensorFlow, NumPy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "colab_type": "code",
    "id": "HY5Y0g3iqqkc",
    "outputId": "bd7160ce-e08b-457b-d0b3-496ba76c404b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version info:\t 1.14.0\n",
      " \n",
      "------------------------------------------------------------\n",
      " \n",
      "NumPy version info:\t \t 1.16.4\n"
     ]
    }
   ],
   "source": [
    "print('TensorFlow version info:\\t',tf.__version__)\n",
    "#!pip show tensorflow\n",
    "print(' ')\n",
    "print('------------------------------------------------------------')\n",
    "print(' ')\n",
    "#!pip show numpy\n",
    "print('NumPy version info:\\t \\t',np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9sX69fS2xhhK"
   },
   "source": [
    "**Making, processing raw data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yirYUEPUb1Sd"
   },
   "source": [
    "Make up data (2x2, sequentially indexed matrices)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YcAFC9e9WE93"
   },
   "outputs": [],
   "source": [
    "series_data = np.zeros((100,2,2), np.float64)        # \"time\"-series data for a 2x2 evolving matrix with 100 time-steps, randomly initialized\n",
    "for i in range(series_data.shape[0]):\n",
    "    series_data[i,:,:] = (i**0.5)*3 + 5\n",
    "#print(series_data)\n",
    "tsteps = int(series_data.shape[0])         # total number of time-steps in the series\n",
    "tsteps_train = int(tsteps/2)               # number of time-steps used for training\n",
    "mat_row = int(series_data.shape[1])\n",
    "mat_col = int(series_data.shape[2])\n",
    "\n",
    "#print(series_data[tsteps_train-2,:,:])\n",
    "#print(series_data[tsteps_train-1,:,:])\n",
    "#print(series_data[tsteps_train,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dn0h4QC2E43v"
   },
   "source": [
    "Define a sequence (multiple consecutive 2x2 matrices) size, ```len_seq```, to be fed in as input (equivalent to the amount of memory in previous time-steps, in our case), and the amount of overlap, ```n_overlap``` between any two adjacent input sequences..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "27iXOLgAPEzr"
   },
   "outputs": [],
   "source": [
    "n_pred = 1 # number of steps to be predicted\n",
    "len_seq = 3 # length of input-sequence\n",
    "n_overlap = 2 # overlap window between consecutive sequences\n",
    "n_seq = int((tsteps_train - (len_seq - n_overlap)) / (len_seq - n_overlap)) # number of sequences of size len_seq\n",
    "\n",
    "if (n_overlap >= len_seq):\n",
    "    raise Exception(\"n_overlap must be less than len_seq\")\n",
    "else:\n",
    "    if (n_pred >= (tsteps_train - (len_seq - 1))):\n",
    "        raise Exception(\"n_pred must be MUCH less than the difference b/w the total time-steps and the length of the input sequence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BJcC3-emQOo6"
   },
   "source": [
    "Build tensor of sequences, call it ```seq_series_data```..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "H9ewF3MOQdiJ",
    "outputId": "c7f453bd-9b18-441d-e2b3-7a6dacfb05fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 3, 2, 2)\n",
      "(49, 1, 2, 2)\n",
      "(49, 3, 4)\n",
      "(49, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "seq_series_data = np.zeros((n_seq, len_seq, mat_row, mat_col), np.float64)\n",
    "seq_series_data_pred = np.zeros((n_seq, n_pred, mat_row, mat_col), np.float64)\n",
    "\n",
    "i = 0\n",
    "k = 0\n",
    "\n",
    "while (i < tsteps and k < n_seq):       # the training sequences start at time-step 1 (series_data[0] element) in this case\n",
    "    try:\n",
    "        for j in range(len_seq):\n",
    "            seq_series_data[k,j,:,:] = series_data[(i+j),:,:]\n",
    "            seq_series_data_pred[k,0:(1+n_pred),:,:] = series_data[(i+j+1):(i+j+n_pred+1),:,:]\n",
    "    except IndexError:\n",
    "        raise Exception(\"ummm... Houston, we've had a problem.\")\n",
    "    #seq_series_data_pred = np.append(seq_series_data_pred, series_data[(i+j+1):(i+j+1+n_pred),:,:], axis = 1)\n",
    "    i += len_seq - n_overlap\n",
    "    k += 1\n",
    "    #print(k,j,i)\n",
    "    #print(seq_series_data[k,:,:,:])\n",
    "\n",
    "#seq_series_data_pred = np.delete(seq_series_data_pred, seq_series_data_pred[0,:,:,:], axis=0) # true output\n",
    "\n",
    "x_inp = np.reshape(seq_series_data[:,:len_seq,:,:], [n_seq, len_seq, (mat_row*mat_col)])\n",
    "y_tru = np.reshape(seq_series_data_pred[:,:,:,:], [n_seq, n_pred, (mat_row*mat_col)])\n",
    "\n",
    "\n",
    "#print(seq_series_data_pred)\n",
    "#print(type(seq_series_data))\n",
    "#print(n_seq)\n",
    "print(seq_series_data.shape)\n",
    "print(seq_series_data_pred.shape)\n",
    "#print(seq_series_data_pred[-1,:,:,:])\n",
    "print(x_inp.shape)\n",
    "print(y_tru.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "LcF6XmVOo4ao",
    "outputId": "b2af00fc-fcc7-426a-e410-df9c7343d5af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X (excluding the true output):  (3, 2, 2)\n",
      "no. of batches of X:  49\n",
      "shape of Y_pred and Y_true:  (1, 2, 2)\n",
      "no. of predictions (equal to the no. of batches of X):  49\n",
      "shape of X (excluding the true output):  (3, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# test to check data-type and shape of seq_series_data, seq_series_data_pred, and a slice seq_series_data\n",
    "\n",
    "print('shape of X (excluding the true output): ',seq_series_data[0,:-1,:,:].shape) \n",
    "print('no. of batches of X: ', seq_series_data.shape[0]) # 1 - prints the number of time-steps, each of these associated with a sequence of 2x2 matrices\n",
    "#print(seq_series_data[0].shape)\n",
    "print('shape of Y_pred and Y_true: ', seq_series_data_pred[:1,:,:].shape)\n",
    "print('no. of predictions (equal to the no. of batches of X): ', seq_series_data_pred.shape[0]) \n",
    "            # 2 - prints the number of time-steps, each of these assocaited with one 2x2 matrix (model truth), must match 1 above\n",
    "print('shape of X (excluding the true output): ', seq_series_data[0,:-1,:,:].shape) # prints the sequence-size used per prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XkAJe24dJM9v"
   },
   "source": [
    "**Building a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NI2T2lW7gNzA"
   },
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KBOJKKq3jlE3"
   },
   "source": [
    "Define activation functions, operations, etc. ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "8c7Z_jERjo_q",
    "outputId": "c2c5c28e-2a77-4124-a341-774261ee69cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# using a convolution operation (with a custom filter), conv_3D, for hidden layer h_2\\n\\n# define a custom filter, filter_1, to be used with the one-shot (stride-less) convolution operation, conv_3D_oneshot\\n#     ignoring padding for now\\ndef filter_1(d, h, w):\\n    # the latest sequence gets the highest contribution\\n    filter = np.zeros((d, h, w), np.float64)\\n    for i in range(d):\\n        for j in range(h):\\n            for k in range(w):\\n                filter[i,j,k] = np.sqrt(np.exp(d))\\n    return tf.convert_to_tensor(filter, dtype=tf.int32)\\n\\n# define a (stride-less) function for the convolution operation\\ndef conv_3D_oneshot(z, name=\"custom_conv_3D_1\"):\\n    shape = z.get_shape().as_list()\\n    depth = shape[0].value\\n    height = shape[1].value\\n    width = shape[2].value\\n    filter = filter_1(depth, height, width)\\n    return tf.math.reduce_sum(tf.math.multiply(z, filter), 0)'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using \"activation=None\" (linear operation) in tf.layers.dense for hidden layer h_1\n",
    "\n",
    "def softplus(z, name=\"softplus\"):\n",
    "    return tf.math.softplus(z)\n",
    "\n",
    "def exponential(z, name=\"exponential\"):\n",
    "    return tf.math.exp(z)\n",
    "\n",
    "def square(z, name=\"square\"):\n",
    "    return tf.math.square(z)\n",
    "\n",
    "def expinv(z, name=\"expinv\"):\n",
    "    return tf.math.exp(-z)\n",
    "\n",
    "def inv(z, name=\"inv\"):\n",
    "    return tf.math.square(tf.math.sqrt(1/z))\n",
    "\n",
    "'''# using a convolution operation (with a custom filter), conv_3D, for hidden layer h_2\n",
    "\n",
    "# define a custom filter, filter_1, to be used with the one-shot (stride-less) convolution operation, conv_3D_oneshot\n",
    "#     ignoring padding for now\n",
    "def filter_1(d, h, w):\n",
    "    # the latest sequence gets the highest contribution\n",
    "    filter = np.zeros((d, h, w), np.float64)\n",
    "    for i in range(d):\n",
    "        for j in range(h):\n",
    "            for k in range(w):\n",
    "                filter[i,j,k] = np.sqrt(np.exp(d))\n",
    "    return tf.convert_to_tensor(filter, dtype=tf.int32)\n",
    "\n",
    "# define a (stride-less) function for the convolution operation\n",
    "def conv_3D_oneshot(z, name=\"custom_conv_3D_1\"):\n",
    "    shape = z.get_shape().as_list()\n",
    "    depth = shape[0].value\n",
    "    height = shape[1].value\n",
    "    width = shape[2].value\n",
    "    filter = filter_1(depth, height, width)\n",
    "    return tf.math.reduce_sum(tf.math.multiply(z, filter), 0)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A8sLsw1_jcKf"
   },
   "source": [
    "Define architectural (hyper-)parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yritMjt8pX2n"
   },
   "outputs": [],
   "source": [
    "# define layers with #(nodes/layer), n_units_i, connected by weight matrices, w_i, and bias matrices, b_i\n",
    "\n",
    "n_inp_n = seq_series_data.shape[0]   # no. of 2x2 matrices fed as input (\"units\" per INPUT layer)\n",
    "n_units_1 = 16   # no. of units in the first hidden layer\n",
    "#n_units_2 = 8\n",
    "#n_units_3 = 4\n",
    "n_units_1_conv = n_units_1\n",
    "            # no. of (convolution) units in the output layer; must equal the number of units in the immediately preceding hidden layer\n",
    "n_outp_n  = n_pred\n",
    "            # number of (2x2) tensors the model must output (the same size as the sequence-size of the model output, 1 in the current case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DCl_pY3wjNNq",
    "outputId": "99b53aad-ebc2-4acd-cc89-fe7bf78cbb85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inp_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "it09yTY1oP4l"
   },
   "source": [
    "Construct input placeholders for the model, build the layers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rmCu5XbAoPN1"
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float64, shape=(None, len_seq, (mat_row*mat_col)), name='input')    # raw input (?x3x4)\n",
    "'''\n",
    "Y_pred = tf.placeholder(tf.float64, shape=(None, mat_row, mat_col),name='model_output')\n",
    "            # model output: predicting a 2x2 matrix \"?\" time-step(s) at a time\n",
    "'''\n",
    "Y_true = tf.placeholder(tf.float64, shape=(None, n_pred, (mat_row*mat_col)), name='true_output')\n",
    "      # true output: same shape as the model output\n",
    "\n",
    "with tf.name_scope(\"ann_1\"):    # test ANN model, \"ann_1\"\n",
    "    h_1 = tf.layers.dense(X, n_units_1, activation=tf.nn.relu, use_bias=True, name=\"hidden_layer_1\")\n",
    "          # first hidden layer (linear activation)\n",
    "    #h_2 = tf.layers.dense(h_1, n_units_2, activation=None, use_bias=False, name=\"hidden_layer_2\")\n",
    "    #h_3 = tf.layers.dense(h_2, n_units_3, activation=None, use_bias=False, name=\"hidden_layer_3\")\n",
    "    f_1 = tf.get_variable(\"inp_to_outp_1\", [n_units_1, n_outp_n], trainable=True, dtype=tf.float64)\n",
    "          # \"filter\" with zero strides, for \"one-shot convolution\"\n",
    "    hf_1 = tf.squeeze(tf.tensordot(h_1, f_1, axes = 1, name=\"hidden_funnel_layer_1\"), 2)\n",
    "          # funneling layer, to reduce input dimensions to output dimensions \n",
    "    f_o = tf.get_variable(\"hf_to_outp_1\", [len_seq, n_outp_n, 1], trainable=True, dtype=tf.float64)\n",
    "    hf_o = tf.tensordot(hf_1, f_o, axes = 1, name=\"output_funnel_layer\")    # output funnel layer\n",
    "    Y_pred = tf.layers.dense(hf_o, (mat_row*mat_col), activation=tf.nn.elu, use_bias=True, name=\"output_layer\")    # model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "GS2SKRLHelL_",
    "outputId": "a2fb5bb9-9127-4556-8a68-16269e046c4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9O5JuU9wQbFm"
   },
   "source": [
    "Define the loss function; choose the optimization algorithm..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_dTnlBToaItF"
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss_ann_1\"):   # loss function for the model \"ann_1\"\n",
    "    loss = tf.losses.mean_squared_error(Y_pred, Y_true)   # element-wise MSE\n",
    "\n",
    "learn_rate = 0.001    # hyper-parameter for updating a variable v: v_new = v_old + delta_v = v_old - learn_rate*grad_v(loss)\n",
    "\n",
    "with tf.name_scope(\"opt_ann_1\"):    # optimizer for \"ann_1\"\n",
    "    opt = tf.train.GradientDescentOptimizer(learn_rate)   # use the gradient descent optimization algorithm\n",
    "    loss_min = opt.minimize(loss)   # operation to minimize \"loss\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-CltqEejDeG8"
   },
   "source": [
    "**Running the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "A7BJ2Icsv4SK",
    "outputId": "6c14edc1-cc53-4fc1-e0f0-3ac93855e035"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(series_data.shape)\\ninp = np.expand_dims(series_data[:99,:,:],-1)\\nout = series_data[1:,:,:]\\nprint(inp.shape)\\nprint(out.shape)'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print(series_data.shape)\n",
    "inp = np.expand_dims(series_data[:99,:,:],-1)\n",
    "out = series_data[1:,:,:]\n",
    "print(inp.shape)\n",
    "print(out.shape)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V2ZCOTsCB_w1"
   },
   "source": [
    "Assign no. of training cycles, batch-sizes, etc.; set up initializer and session-saver objects ```init``` and ```saver``` (required for assigning initial values to the ```tf.Graph``` variables and saving the values of variables optimized in the session); use a context manager to run the ```tf.Session```..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CO4BdO_CB1am",
    "outputId": "4ba66d6a-8eeb-46d3-f184-3ed2227dd7f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MSE (training): 278.49365 \n",
      " (49, 1, 4)\n",
      "1000 MSE (training): 235.66342 \n",
      " (49, 1, 4)\n",
      "2000 MSE (training): 99.48665 \n",
      " (49, 1, 4)\n",
      "3000 MSE (training): 49.402534 \n",
      " (49, 1, 4)\n",
      "4000 MSE (training): 30.982227 \n",
      " (49, 1, 4)\n",
      "5000 MSE (training): 24.207468 \n",
      " (49, 1, 4)\n",
      "6000 MSE (training): 21.715797 \n",
      " (49, 1, 4)\n",
      "7000 MSE (training): 20.799393 \n",
      " (49, 1, 4)\n",
      "8000 MSE (training): 20.46235 \n",
      " (49, 1, 4)\n",
      "9000 MSE (training): 20.338388 \n",
      " (49, 1, 4)\n",
      "10000 MSE (training): 20.292797 \n",
      " (49, 1, 4)\n",
      "11000 MSE (training): 20.276031 \n",
      " (49, 1, 4)\n",
      "12000 MSE (training): 20.269865 \n",
      " (49, 1, 4)\n",
      "13000 MSE (training): 20.267597 \n",
      " (49, 1, 4)\n",
      "14000 MSE (training): 20.266764 \n",
      " (49, 1, 4)\n",
      "15000 MSE (training): 20.266455 \n",
      " (49, 1, 4)\n",
      "16000 MSE (training): 20.266342 \n",
      " (49, 1, 4)\n",
      "17000 MSE (training): 20.266302 \n",
      " (49, 1, 4)\n",
      "18000 MSE (training): 20.266283 \n",
      " (49, 1, 4)\n",
      "19000 MSE (training): 20.266281 \n",
      " (49, 1, 4)\n",
      "<tf.Variable 'hidden_layer_1/kernel:0' shape=(4, 16) dtype=float64_ref>\n",
      "[[-0.39961986 -0.39992093 -0.46756312 -0.26192758 -0.1675904  -0.44382558\n",
      "   0.04578793 -0.56449983 -0.43998007 -0.32059272  0.12834125  0.31683937\n",
      "  -0.09486832  0.00666263 -0.02772555 -0.33417501]\n",
      " [-0.17001624 -0.27574383 -0.06464861  0.02876619  0.09120526 -0.27367438\n",
      "   0.22188295  0.14130394 -0.08696844 -0.52758348 -0.24266674 -0.3956129\n",
      "   0.3744706   0.11839083 -0.01373398  0.35488415]\n",
      " [ 0.30575523 -0.37769079  0.50758465  0.13452104  0.20447071  0.50534582\n",
      "   0.0656333   0.33900706  0.14389494  0.49088073 -0.00924707 -0.39373593\n",
      "  -0.08498427 -0.60668042  0.47225329 -0.28524832]\n",
      " [ 0.23859314 -0.51434436 -0.24372524  0.06881154 -0.1312356  -0.37915552\n",
      "  -0.34778599  0.03954046  0.22821811  0.34479612  0.08766991  0.17626676\n",
      "  -0.40179215  0.44174835 -0.50358115 -0.12220244]]\n",
      "<tf.Variable 'hidden_layer_1/bias:0' shape=(16,) dtype=float64_ref>\n",
      "[-0.00409528  0.          0.          0.00226799 -0.00062251  0.\n",
      " -0.00338669  0.00210242 -0.00283148  0.00173602 -0.00625382  0.\n",
      "  0.          0.00553131 -0.00204047  0.        ]\n",
      "<tf.Variable 'inp_to_outp_1:0' shape=(16, 1) dtype=float64_ref>\n",
      "[[ 0.19855473]\n",
      " [ 0.07472554]\n",
      " [-0.1532808 ]\n",
      " [ 0.01485396]\n",
      " [ 0.00158989]\n",
      " [ 0.34877258]\n",
      " [ 0.00732225]\n",
      " [ 0.02226559]\n",
      " [ 0.48007734]\n",
      " [ 0.00620497]\n",
      " [ 0.01810015]\n",
      " [-0.22977067]\n",
      " [ 0.09706117]\n",
      " [ 0.01979685]\n",
      " [ 0.34136432]\n",
      " [-0.2324733 ]]\n",
      "<tf.Variable 'hf_to_outp_1:0' shape=(3, 1, 1) dtype=float64_ref>\n",
      "[[[-0.01216075]]\n",
      "\n",
      " [[ 0.54690043]]\n",
      "\n",
      " [[-0.45927778]]]\n",
      "<tf.Variable 'output_layer/kernel:0' shape=(1, 4) dtype=float64_ref>\n",
      "[[ 0.00088862  0.00088867  0.00088916 -0.00046925]]\n",
      "<tf.Variable 'output_layer/bias:0' shape=(4,) dtype=float64_ref>\n",
      "[19.92318609 19.92318599 19.92318505 19.92312284]\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 20000   # number of optimization steps on the WHOLE training dataset\n",
    "\n",
    "init = tf.global_variables_initializer()    # initialize the model variables\n",
    "saver = tf.train.Saver()    # saves the updated parameters from a session run\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \"\"\"#inp = np.expand_dims(series_data[:n_inp_n,:,:],-1)\n",
    "    #out = np.expand_dims(series_data[n_inp_n,:,:],0)\n",
    "    #n_outp_n = 3\n",
    "    n_len = len(series_data)\n",
    "    #print(n_len,n_outp_n)\n",
    "    inp = np.expand_dims(series_data[:(n_len - n_outp_n),:,:],-1)\n",
    "    out = np.reshape(series_data[(n_len - n_outp_n):,:,:], [1,mat_row,mat_col,n_outp_n])\n",
    "    print(inp.shape)\n",
    "    print(out.shape)\n",
    "    \"\"\"\n",
    "    y_out = Y_pred.eval(feed_dict={X: x_inp})\n",
    "    #print(y_out)\n",
    "    for train_epoch in range(n_epoch):\n",
    "        #for batch_iter in range(seq_series_data.shape[0]):\n",
    "        #print(inp.shape, out.shape)\n",
    "        #print(X_in.get_shape(),Y_pred.get_shape(), Y_true.get_shape(), hf_1.get_shape(), f_1.get_shape(), h_1.get_shape())\n",
    "        sess.run(loss_min, feed_dict={X: x_inp, Y_true: y_tru})\n",
    "        if (train_epoch % 1000 == 0):\n",
    "            y_out = Y_pred.eval(feed_dict={X: x_inp})\n",
    "            #layer_2 = hf_1.eval(feed_dict={X: inp})\n",
    "            #layer_3 = h_2.eval(feed_dict={X: inp})\n",
    "            acc_train = loss.eval(feed_dict={X: x_inp, Y_true: y_tru})\n",
    "            print(train_epoch, \"MSE (training):\", acc_train, \"\\n\", y_out.shape)#, \"\\n\", layer_2, \"\\n\", layer_3)\n",
    "\n",
    "    vars = tf.trainable_variables()\n",
    "    for v in vars:\n",
    "        print(v)\n",
    "        print(sess.run(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWcQbDHlmfSl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "tf1_test_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf1_14_0_gpu",
   "language": "python",
   "name": "tf1_14_0_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
