{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf1_test_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karnamohit/kranka_ucm/blob/master/tf1_test_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtgEx4iIVXly",
        "colab_type": "text"
      },
      "source": [
        "Importing all the useful libraries..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_vn7WnlmKCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGuZTN4AhVKa",
        "colab_type": "code",
        "outputId": "1a3a06e4-f65f-487c-de00-f825a8229cba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYKUs0zghlEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!ls /content/drive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8knKLFRVFvY",
        "colab_type": "text"
      },
      "source": [
        "Checking the version of TensorFlow, NumPy..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY5Y0g3iqqkc",
        "colab_type": "code",
        "outputId": "bd7160ce-e08b-457b-d0b3-496ba76c404b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "#print('TensorFlow version info:\\t',tf.__version__)\n",
        "!pip show tensorflow\n",
        "print(' ')\n",
        "print('------------------------------------------------------------')\n",
        "print(' ')\n",
        "!pip show numpy\n",
        "#print('NumPy version info:\\t \\t',np.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.15.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: google-pasta, numpy, tensorboard, wheel, gast, termcolor, grpcio, absl-py, astor, protobuf, six, keras-applications, opt-einsum, tensorflow-estimator, keras-preprocessing, wrapt\n",
            "Required-by: stable-baselines, magenta, fancyimpute\n",
            " \n",
            "------------------------------------------------------------\n",
            " \n",
            "Name: numpy\n",
            "Version: 1.17.3\n",
            "Summary: NumPy is the fundamental package for array computing with Python.\n",
            "Home-page: https://www.numpy.org\n",
            "Author: Travis E. Oliphant et al.\n",
            "Author-email: None\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: \n",
            "Required-by: yellowbrick, xgboost, xarray, wordcloud, umap-learn, torchvision, torchtext, torch, thinc, Theano, tflearn, tensorflow, tensorflow-probability, tensorflow-hub, tensorflow-datasets, tensorboard, tensor2tensor, tables, statsmodels, stable-baselines, spacy, sklearn-pandas, seaborn, scs, scipy, scikit-learn, resampy, PyWavelets, pystan, pysndfile, pymc3, pyemd, pyarrow, pretty-midi, plotnine, patsy, pandas, osqp, opt-einsum, opencv-python, opencv-contrib-python, numexpr, numba, np-utils, nibabel, moviepy, mlxtend, mizani, missingno, mir-eval, matplotlib, matplotlib-venn, magenta, lucid, lightgbm, librosa, knnimpute, kfac, Keras, Keras-Preprocessing, Keras-Applications, kapre, jpeg4py, jaxlib, jax, imgaug, imbalanced-learn, imageio, hyperopt, h5py, gym, graph-nets, gensim, folium, fix-yahoo-finance, featuretools, fbprophet, fastdtw, fastai, fancyimpute, fa2, ecos, daft, cvxpy, cupy-cuda100, cufflinks, chainer, Bottleneck, bokeh, blis, autograd, atari-py, astropy, altair, albumentations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sX69fS2xhhK",
        "colab_type": "text"
      },
      "source": [
        "**Making, processing raw data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yirYUEPUb1Sd",
        "colab_type": "text"
      },
      "source": [
        "Make up data (2x2, sequentially indexed matrices)..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcAFC9e9WE93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "series_data = np.zeros((100,2,2), np.float64)        # \"time\"-series data for a 2x2 evolving matrix with 100 time-steps, randomly initialized\n",
        "for i in range(series_data.shape[0]):\n",
        "    series_data[i,:,:] = (i**0.5)*3 + 5\n",
        "#print(series_data)\n",
        "tsteps = int(series_data.shape[0])         # total number of time-steps in the series\n",
        "tsteps_train = int(tsteps/2)               # number of time-steps used for training\n",
        "mat_row = int(series_data.shape[1])\n",
        "mat_col = int(series_data.shape[2])\n",
        "\n",
        "#print(series_data[tsteps_train-2,:,:])\n",
        "#print(series_data[tsteps_train-1,:,:])\n",
        "#print(series_data[tsteps_train,:,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn0h4QC2E43v",
        "colab_type": "text"
      },
      "source": [
        "Define a sequence (multiple consecutive 2x2 matrices) size, ```len_seq```, to be fed in as input (equivalent to the amount of memory in previous time-steps, in our case), and the amount of overlap, ```n_overlap``` between any two adjacent input sequences..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27iXOLgAPEzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len_seq = 4\n",
        "n_overlap = 3\n",
        "\n",
        "if (n_overlap >= len_seq):\n",
        "    raise Exception(\"n_overlap must be less than len_seq\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJcC3-emQOo6",
        "colab_type": "text"
      },
      "source": [
        "Build tensor of sequences, call it ```seq_series_data```..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9ewF3MOQdiJ",
        "colab_type": "code",
        "outputId": "c7f453bd-9b18-441d-e2b3-7a6dacfb05fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "n_seq = int((tsteps_train - (len_seq - n_overlap)) / (len_seq - n_overlap)) # number of sequences of size len_seq\n",
        "#print(n_seq)\n",
        "seq_series_data = np.zeros((n_seq,len_seq,mat_row,mat_col), np.float64)\n",
        "seq_series_data_pred = np.zeros((1,mat_row,mat_col), np.float64)\n",
        "#print(seq_series_data_pred)\n",
        "i = 0\n",
        "#j = 0\n",
        "k = 0\n",
        "while (i <= n_seq):           # the training sequences start at time-step 1 (series_data[0] element) in this case\n",
        "    try:\n",
        "        for j in range(len_seq - 1):\n",
        "            seq_series_data[k,j,:,:] = series_data[i+j,:,:]\n",
        "    except IndexError:\n",
        "        break\n",
        "    #print(seq_series_data[k,:,:,:])\n",
        "    #print(j)\n",
        "    seq_series_data_pred = np.append(seq_series_data_pred, series_data[i+j+1:i+j+2,:,:], axis = 0)\n",
        "    i += len_seq - n_overlap\n",
        "    #j += 1\n",
        "    k += 1\n",
        "    #print(k,i)\n",
        "seq_series_data_pred = np.delete(seq_series_data_pred, seq_series_data_pred[0,:,:], axis=0) # true output\n",
        "#print(seq_series_data_pred)\n",
        "#print(type(seq_series_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcF6XmVOo4ao",
        "colab_type": "code",
        "outputId": "b2af00fc-fcc7-426a-e410-df9c7343d5af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# test to check data-type and shape of seq_series_data, seq_series_data_pred, and a slice seq_series_data\n",
        "\n",
        "print('shape of X (excluding the true output): ',seq_series_data[0,:-1,:,:].shape) \n",
        "print('no. of batches of X: ', seq_series_data.shape[0]) # 1 - prints the number of time-steps, each of these associated with a sequence of 2x2 matrices\n",
        "#print(seq_series_data[0].shape)\n",
        "print('shape of Y_pred and Y_true: ', seq_series_data_pred[:1,:,:].shape)\n",
        "print('no. of predictions (equal to the no. of batches of X): ', seq_series_data_pred.shape[0]) \n",
        "            # 2 - prints the number of time-steps, each of these assocaited with one 2x2 matrix (model truth), must match 1 above\n",
        "print('shape of X (excluding the true output): ', seq_series_data[0,:-1,:,:].shape) # prints the sequence-size used per prediction"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of X (excluding the true output):  (3, 2, 2)\n",
            "no. of batches of X:  49\n",
            "shape of Y_pred and Y_true:  (1, 2, 2)\n",
            "no. of predictions (equal to the no. of batches of X):  49\n",
            "shape of X (excluding the true output):  (3, 2, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkAJe24dJM9v",
        "colab_type": "text"
      },
      "source": [
        "**Building a model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI2T2lW7gNzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBOJKKq3jlE3",
        "colab_type": "text"
      },
      "source": [
        "Define activation functions, operations, etc. ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c7Z_jERjo_q",
        "colab_type": "code",
        "outputId": "c2c5c28e-2a77-4124-a341-774261ee69cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# using \"activation=None\" (linear operation) in tf.layers.dense for hidden layer h_1\n",
        "\n",
        "def softplus(z, name=\"softplus\"):\n",
        "    return tf.math.softplus(z)\n",
        "\n",
        "def exponential(z, name=\"exponential\"):\n",
        "    return tf.math.exp(z)\n",
        "\n",
        "def square(z, name=\"square\"):\n",
        "    return tf.math.square(z)\n",
        "\n",
        "def expinv(z, name=\"expinv\"):\n",
        "    return tf.math.exp(-z)\n",
        "\n",
        "def inv(z, name=\"inv\"):\n",
        "    return tf.math.square(tf.math.sqrt(1/z))\n",
        "\n",
        "'''# using a convolution operation (with a custom filter), conv_3D, for hidden layer h_2\n",
        "\n",
        "# define a custom filter, filter_1, to be used with the one-shot (stride-less) convolution operation, conv_3D_oneshot\n",
        "#     ignoring padding for now\n",
        "def filter_1(d, h, w):\n",
        "    # the latest sequence gets the highest contribution\n",
        "    filter = np.zeros((d, h, w), np.float64)\n",
        "    for i in range(d):\n",
        "        for j in range(h):\n",
        "            for k in range(w):\n",
        "                filter[i,j,k] = np.sqrt(np.exp(d))\n",
        "    return tf.convert_to_tensor(filter, dtype=tf.int32)\n",
        "\n",
        "# define a (stride-less) function for the convolution operation\n",
        "def conv_3D_oneshot(z, name=\"custom_conv_3D_1\"):\n",
        "    shape = z.get_shape().as_list()\n",
        "    depth = shape[0].value\n",
        "    height = shape[1].value\n",
        "    width = shape[2].value\n",
        "    filter = filter_1(depth, height, width)\n",
        "    return tf.math.reduce_sum(tf.math.multiply(z, filter), 0)'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# using a convolution operation (with a custom filter), conv_3D, for hidden layer h_2\\n\\n# define a custom filter, filter_1, to be used with the one-shot (stride-less) convolution operation, conv_3D_oneshot\\n#     ignoring padding for now\\ndef filter_1(d, h, w):\\n    # the latest sequence gets the highest contribution\\n    filter = np.zeros((d, h, w), np.float64)\\n    for i in range(d):\\n        for j in range(h):\\n            for k in range(w):\\n                filter[i,j,k] = np.sqrt(np.exp(d))\\n    return tf.convert_to_tensor(filter, dtype=tf.int32)\\n\\n# define a (stride-less) function for the convolution operation\\ndef conv_3D_oneshot(z, name=\"custom_conv_3D_1\"):\\n    shape = z.get_shape().as_list()\\n    depth = shape[0].value\\n    height = shape[1].value\\n    width = shape[2].value\\n    filter = filter_1(depth, height, width)\\n    return tf.math.reduce_sum(tf.math.multiply(z, filter), 0)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8sLsw1_jcKf",
        "colab_type": "text"
      },
      "source": [
        "Define architectural (hyper-)parameters..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yritMjt8pX2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define layers with #(nodes/layer), n_units_i, connected by weight matrices, w_i, and bias matrices, b_i\n",
        "\n",
        "n_inp_n = series_data[:tsteps_train,:,:].shape[0]   # no. of 2x2 matrices fed as input (\"units\" per INPUT layer)\n",
        "n_units_1 = 4   # no. of units in the first hidden layer\n",
        "#n_units_2 = 8\n",
        "#n_units_3 = 4\n",
        "n_units_1_conv = n_units_1\n",
        "            # no. of (convolution) units in the output layer; must equal the number of units in the immediately preceding hidden layer\n",
        "n_outp_n  = 3\n",
        "            # number of (2x2) tensors the model must output (the same size as the sequence-size of the model output, 1 in the current case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCl_pY3wjNNq",
        "colab_type": "code",
        "outputId": "99b53aad-ebc2-4acd-cc89-fe7bf78cbb85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "n_inp_n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it09yTY1oP4l",
        "colab_type": "text"
      },
      "source": [
        "Construct input placeholders for the model, build the layers..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmCu5XbAoPN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float64, shape=(None, mat_row, mat_col, 1), name='input')    # raw input (?x2x2)\n",
        "#X_in = tf.expand_dims(X,-1)\n",
        "#x1 = tf.math.exp(X)    # model input (modified raw input) (3x2x2)\n",
        "# Y_pred = tf.placeholder(tf.float64, shape=(None, mat_row, mat_col),name='model_output')\n",
        "            # model output: predicting a 2x2 matrix \"?\" time-step(s) at a time\n",
        "Y_true = tf.placeholder(tf.float64, shape=(None, mat_row, mat_col, n_outp_n),name='true_output')   # true output: same shape as the model output\n",
        "#dim_in = tf.placeholder(tf.int64, shape=(1), name='len_inp')\n",
        "#dim_out = tf.placeholder(tf.int64,shape=(1), name='len_out')\n",
        "X.get_shape()\n",
        "\n",
        "with tf.name_scope(\"ann_1\"):    # test ANN model, \"ann_1\"\n",
        "    h_1 = tf.layers.dense(X, n_units_1, activation=tf.nn.relu, use_bias=True, name=\"hidden_layer_1\")    # first hidden layer (linear activation)\n",
        "    #h_2 = tf.layers.dense(h_1, n_units_2, activation=None, use_bias=False, name=\"hidden_layer_2\")\n",
        "    #h_3 = tf.layers.dense(h_2, n_units_3, activation=None, use_bias=False, name=\"hidden_layer_3\")\n",
        "    f_1 = tf.get_variable(\"inp_to_outp_1\", [n_units_1, n_outp_n], trainable=True, dtype=tf.float64)    # \"filter\" with zero strides, for \"one-shot convolution\"\n",
        "    hf_1 = tf.tensordot(h_1, f_1, axes = 1, name=\"hidden_funnel_layer_1\")   # funneling layer, to reduce input dimensions to output dimensions \n",
        "    h_o = tf.layers.dense(hf_1, n_outp_n, activation=None, use_bias=True, name=\"output_layer\")    # output layer\n",
        "    Y_pred = h_o    # model output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS2SKRLHelL_",
        "colab_type": "code",
        "outputId": "a2fb5bb9-9127-4556-8a68-16269e046c4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Y_pred.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(2), Dimension(2), Dimension(3)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O5JuU9wQbFm",
        "colab_type": "text"
      },
      "source": [
        "Define the loss function; choose the optimization algorithm..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dTnlBToaItF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.name_scope(\"loss_ann_1\"):   # loss function for the model \"ann_1\"\n",
        "    loss = tf.losses.mean_squared_error(Y_pred, Y_true)   # element-wise MSE\n",
        "\n",
        "learn_rate = 0.001    # hyper-parameter for updating a variable v: v_new = v_old + delta_v = v_old - learn_rate*grad_v(loss)\n",
        "\n",
        "with tf.name_scope(\"opt_ann_1\"):    # optimizer for \"ann_1\"\n",
        "    opt = tf.train.GradientDescentOptimizer(learn_rate)   # use the gradient descent optimization algorithm\n",
        "    loss_min = opt.minimize(loss)   # operation to minimize \"loss\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CltqEejDeG8",
        "colab_type": "text"
      },
      "source": [
        "**Running the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7BJ2Icsv4SK",
        "colab_type": "code",
        "outputId": "6c14edc1-cc53-4fc1-e0f0-3ac93855e035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''print(series_data.shape)\n",
        "inp = np.expand_dims(series_data[:99,:,:],-1)\n",
        "out = series_data[1:,:,:]\n",
        "print(inp.shape)\n",
        "print(out.shape)'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(series_data.shape)\\ninp = np.expand_dims(series_data[:99,:,:],-1)\\nout = series_data[1:,:,:]\\nprint(inp.shape)\\nprint(out.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2ZCOTsCB_w1",
        "colab_type": "text"
      },
      "source": [
        "Assign no. of training cycles, batch-sizes, etc.; set up initializer and session-saver objects ```init``` and ```saver``` (required for assigning initial values to the ```tf.Graph``` variables and saving the values of variables optimized in the session); use a context manager to run the ```tf.Session```..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO4BdO_CB1am",
        "colab_type": "code",
        "outputId": "4ba66d6a-8eeb-46d3-f184-3ed2227dd7f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_epoch = 10000   # number of optimization steps on the WHOLE training dataset\n",
        "\n",
        "init = tf.global_variables_initializer()    # initialize the model variables\n",
        "saver = tf.train.Saver()    # saves the updated parameters from a session run\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    #inp = np.expand_dims(series_data[:n_inp_n,:,:],-1)\n",
        "    #out = np.expand_dims(series_data[n_inp_n,:,:],0)\n",
        "    #n_outp_n = 3\n",
        "    n_len = len(series_data)\n",
        "    #print(n_len,n_outp_n)\n",
        "    inp = np.expand_dims(series_data[:(n_len - n_outp_n),:,:],-1)\n",
        "    out = np.reshape(series_data[(n_len - n_outp_n):,:,:], [1,mat_row,mat_col,n_outp_n])\n",
        "    print(inp.shape)\n",
        "    print(out.shape)\n",
        "    yy = Y_pred.eval(feed_dict={X: inp})\n",
        "    print(yy)\n",
        "    for train_epoch in range(n_epoch):\n",
        "        #for batch_iter in range(seq_series_data.shape[0]):\n",
        "        #print(inp.shape, out.shape)\n",
        "        #print(X_in.get_shape(),Y_pred.get_shape(), Y_true.get_shape(), hf_1.get_shape(), f_1.get_shape(), h_1.get_shape())\n",
        "        sess.run(loss_min, feed_dict={X: inp, Y_true: out})\n",
        "        if (train_epoch % 1000 == 0):\n",
        "            y = Y_pred.eval(feed_dict={X: inp})\n",
        "            #layer_2 = hf_1.eval(feed_dict={X: inp})\n",
        "            #layer_3 = h_2.eval(feed_dict={X: inp})\n",
        "            acc_train = loss.eval(feed_dict={X: inp, Y_true: out})\n",
        "            print(train_epoch, \"MSE (training):\", acc_train, \"\\n\", y.shape)#, \"\\n\", layer_2, \"\\n\", layer_3)\n",
        "\n",
        "    vars = tf.trainable_variables()\n",
        "    for v in vars:\n",
        "        print(v)\n",
        "        print(sess.run(v))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(97, 2, 2, 1)\n",
            "(1, 2, 2, 3)\n",
            "[[[[0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0.]\n",
            "   [0. 0. 0.]]\n",
            "\n",
            "  [[0. 0. 0.]\n",
            "   [0. 0. 0.]]]]\n",
            "0 MSE (training): 1202.3776 \n",
            " (97, 2, 2, 3)\n",
            "1000 MSE (training): 316.8129 \n",
            " (97, 2, 2, 3)\n",
            "2000 MSE (training): 83.48441 \n",
            " (97, 2, 2, 3)\n",
            "3000 MSE (training): 22.007044 \n",
            " (97, 2, 2, 3)\n",
            "4000 MSE (training): 5.808984 \n",
            " (97, 2, 2, 3)\n",
            "5000 MSE (training): 1.5411203 \n",
            " (97, 2, 2, 3)\n",
            "6000 MSE (training): 0.41662413 \n",
            " (97, 2, 2, 3)\n",
            "7000 MSE (training): 0.12034041 \n",
            " (97, 2, 2, 3)\n",
            "8000 MSE (training): 0.042276364 \n",
            " (97, 2, 2, 3)\n",
            "9000 MSE (training): 0.021707986 \n",
            " (97, 2, 2, 3)\n",
            "<tf.Variable 'hidden_layer_1/kernel:0' shape=(1, 4) dtype=float64_ref>\n",
            "[[-0.63604673 -0.79984185 -0.93512625 -0.30171197]]\n",
            "<tf.Variable 'hidden_layer_1/bias:0' shape=(4,) dtype=float64_ref>\n",
            "[0. 0. 0. 0.]\n",
            "<tf.Variable 'inp_to_outp_1:0' shape=(4, 3) dtype=float64_ref>\n",
            "[[ 0.4529575   0.11645135 -0.23887088]\n",
            " [-0.44139857  0.00673471  0.5435228 ]\n",
            " [ 0.06344071 -0.58071371  0.76237771]\n",
            " [-0.23358394  0.02469785 -0.35807173]]\n",
            "<tf.Variable 'output_layer/kernel:0' shape=(3, 3) dtype=float64_ref>\n",
            "[[-0.84583549  0.19615233 -0.90658756]\n",
            " [ 0.73971118  0.01503948 -0.70857845]\n",
            " [-0.63244174 -0.69015273 -0.62695093]]\n",
            "<tf.Variable 'output_layer/bias:0' shape=(3,) dtype=float64_ref>\n",
            "[34.61630264 34.65423262 34.6919692 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNDj8-SUjRMy",
        "colab_type": "code",
        "outputId": "eae6ff32-8ded-4572-d1ec-8b1a3a620b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWcQbDHlmfSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}