{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf1_test_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karnamohit/kranka_ucm/blob/master/tf1_test_1-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtgEx4iIVXly",
        "colab_type": "text"
      },
      "source": [
        "Importing all the useful libraries..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_vn7WnlmKCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8knKLFRVFvY",
        "colab_type": "text"
      },
      "source": [
        "Checking the version of TensorFlow, NumPy..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY5Y0g3iqqkc",
        "colab_type": "code",
        "outputId": "42ac99bd-f1fa-411d-838b-c6bdf0b7c4d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "#print('TensorFlow version info:\\t',tf.__version__)\n",
        "!pip show tensorflow\n",
        "print(' ')\n",
        "print('------------------------------------------------------------')\n",
        "print(' ')\n",
        "!pip show numpy\n",
        "#print('NumPy version info:\\t \\t',np.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.15.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: keras-applications, six, wrapt, google-pasta, keras-preprocessing, grpcio, tensorflow-estimator, protobuf, absl-py, opt-einsum, numpy, termcolor, tensorboard, astor, gast, wheel\n",
            "Required-by: stable-baselines, mesh-tensorflow, magenta, fancyimpute\n",
            " \n",
            "------------------------------------------------------------\n",
            " \n",
            "Name: numpy\n",
            "Version: 1.16.5\n",
            "Summary: NumPy is the fundamental package for array computing with Python.\n",
            "Home-page: https://www.numpy.org\n",
            "Author: Travis E. Oliphant et al.\n",
            "Author-email: None\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: \n",
            "Required-by: yellowbrick, xgboost, xarray, wordcloud, umap-learn, torchvision, torchtext, torch, thinc, Theano, tflearn, tensorflow, tensorflow-probability, tensorflow-hub, tensorflow-datasets, tensorboard, tensor2tensor, tables, statsmodels, stable-baselines, spacy, sklearn-pandas, seaborn, scs, scipy, scikit-learn, resampy, PyWavelets, pystan, pysndfile, pymc3, pyemd, pyarrow, pretty-midi, plotnine, patsy, pandas, osqp, opt-einsum, opencv-python, opencv-contrib-python, numexpr, numba, np-utils, nibabel, moviepy, mlxtend, mizani, missingno, mir-eval, matplotlib, matplotlib-venn, magenta, lucid, lightgbm, librosa, knnimpute, kfac, Keras, Keras-Preprocessing, Keras-Applications, kapre, jpeg4py, jaxlib, jax, imgaug, imbalanced-learn, imageio, hyperopt, h5py, gym, graph-nets, gensim, folium, fix-yahoo-finance, featuretools, fbprophet, fastdtw, fastai, fancyimpute, fa2, ecos, daft, cvxpy, cupy-cuda100, chainer, Bottleneck, bokeh, blis, autograd, atari-py, astropy, altair, albumentations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sX69fS2xhhK",
        "colab_type": "text"
      },
      "source": [
        "**Making, processing raw data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yirYUEPUb1Sd",
        "colab_type": "text"
      },
      "source": [
        "Make up data (2x2, sequentially indexed matrices)..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcAFC9e9WE93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "series_data = np.zeros((100,2,2), np.float64)        # \"time\"-series data for a 2x2 evolving matrix with 100 time-steps, randomly initialized\n",
        "for i in range(series_data.shape[0]):\n",
        "    series_data[i,:,:] = (i**0.5)*3 + 5\n",
        "#print(series_data)\n",
        "tsteps = int(series_data.shape[0])         # total number of time-steps in the series\n",
        "tsteps_train = int(tsteps/2)               # number of time-steps used for training\n",
        "mat_row = int(series_data.shape[1])\n",
        "mat_col = int(series_data.shape[2])\n",
        "\n",
        "#print(series_data[tsteps_train-2,:,:])\n",
        "#print(series_data[tsteps_train-1,:,:])\n",
        "#print(series_data[tsteps_train,:,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn0h4QC2E43v",
        "colab_type": "text"
      },
      "source": [
        "Define a sequence (multiple consecutive 2x2 matrices) size, ```len_seq```, to be fed in as input (equivalent to the amount of memory in previous time-steps, in our case), and the amount of overlap, ```n_overlap``` between any two adjacent input sequences..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27iXOLgAPEzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len_seq = 4\n",
        "n_overlap = 3\n",
        "\n",
        "if (n_overlap >= len_seq):\n",
        "    raise Exception(\"n_overlap must be less than len_seq\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJcC3-emQOo6",
        "colab_type": "text"
      },
      "source": [
        "Build tensor of sequences, call it ```seq_series_data```..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9ewF3MOQdiJ",
        "colab_type": "code",
        "outputId": "656f6b6d-6d5d-44d1-ce4e-3fdd0a3ddebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "n_seq = int((tsteps_train - (len_seq - n_overlap)) / (len_seq - n_overlap)) # number of sequences of size len_seq\n",
        "#print(n_seq)\n",
        "seq_series_data = np.zeros((n_seq,len_seq,mat_row,mat_col), np.float64)\n",
        "seq_series_data_pred = np.zeros((1,mat_row,mat_col), np.float64)\n",
        "#print(seq_series_data_pred)\n",
        "i = 0\n",
        "#j = 0\n",
        "k = 0\n",
        "while (i <= n_seq):           # the training sequences start at time-step 1 (series_data[0] element) in this case\n",
        "    try:\n",
        "        for j in range(len_seq - 1):\n",
        "            seq_series_data[k,j,:,:] = series_data[i+j,:,:]\n",
        "    except IndexError:\n",
        "        break\n",
        "    #print(seq_series_data[k,:,:,:])\n",
        "    #print(j)\n",
        "    seq_series_data_pred = np.append(seq_series_data_pred, series_data[i+j+1:i+j+2,:,:], axis = 0)\n",
        "    i += len_seq - n_overlap\n",
        "    #j += 1\n",
        "    k += 1\n",
        "    #print(k,i)\n",
        "seq_series_data_pred = np.delete(seq_series_data_pred, seq_series_data_pred[0,:,:], axis=0) # true output\n",
        "#print(seq_series_data_pred)\n",
        "#print(type(seq_series_data))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcF6XmVOo4ao",
        "colab_type": "code",
        "outputId": "c9086739-4902-42ec-e4d0-0e3da2096bc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# test to check data-type and shape of seq_series_data, seq_series_data_pred, and a slice seq_series_data\n",
        "\n",
        "print('shape of X (excluding the true output): ',seq_series_data[0,:-1,:,:].shape) \n",
        "print('no. of batches of X: ', seq_series_data.shape[0]) # 1 - prints the number of time-steps, each of these associated with a sequence of 2x2 matrices\n",
        "#print(seq_series_data[0].shape)\n",
        "print('shape of Y_pred and Y_true: ', seq_series_data_pred[:1,:,:].shape)\n",
        "print('no. of predictions (equal to the no. of batches of X): ', seq_series_data_pred.shape[0]) \n",
        "            # 2 - prints the number of time-steps, each of these assocaited with one 2x2 matrix (model truth), must match 1 above\n",
        "print('shape of X (excluding the true output): ', seq_series_data[0,:-1,:,:].shape) # prints the sequence-size used per prediction"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of X (excluding the true output):  (3, 2, 2)\n",
            "no. of batches of X:  49\n",
            "shape of Y_pred and Y_true:  (1, 2, 2)\n",
            "no. of predictions (equal to the no. of batches of X):  49\n",
            "shape of X (excluding the true output):  (3, 2, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-1rfAmFoh5V",
        "colab_type": "text"
      },
      "source": [
        "**Declaring parameters and variables to be used in the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it09yTY1oP4l",
        "colab_type": "text"
      },
      "source": [
        "Construct input placeholders for the model..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmCu5XbAoPN1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "66434d5b-0558-4c18-a3fa-89b55c2ce424"
      },
      "source": [
        "X = tf.placeholder(tf.float64, shape=(None, mat_row, mat_col), name='input')    # raw input (?x2x2)\n",
        "X = tf.expand_dims(X,-1)\n",
        "#x1 = tf.math.exp(X)    # model input (modified raw input) (3x2x2)\n",
        "Y_pred = tf.placeholder(tf.float64, shape=(None, mat_row, mat_col),name='model_output')\n",
        "            # model output: predicting a 2x2 matrix \"?\" time-step(s) at a time\n",
        "Y_true = tf.placeholder(tf.float64, shape=(None, mat_row,mat_col),name='true_output')   # true output: same shape as the model output\n",
        "X.get_shape()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(2), Dimension(2), Dimension(1)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkAJe24dJM9v",
        "colab_type": "text"
      },
      "source": [
        "**Building a model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBOJKKq3jlE3",
        "colab_type": "text"
      },
      "source": [
        "Define activation functions, operations, etc. ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c7Z_jERjo_q",
        "colab_type": "code",
        "outputId": "dc4d1968-4662-4b54-cd78-5a787ce9f107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# using \"activation=None\" (linear operation) in tf.layers.dense for hidden layer h_1\n",
        "\n",
        "def softplus(z, name=\"softplus\"):\n",
        "    return tf.math.softplus(z)\n",
        "\n",
        "'''# using a convolution operation (with a custom filter), conv_3D, for hidden layer h_2\n",
        "\n",
        "# define a custom filter, filter_1, to be used with the one-shot (stride-less) convolution operation, conv_3D_oneshot\n",
        "#     ignoring padding for now\n",
        "def filter_1(d, h, w):\n",
        "    # the latest sequence gets the highest contribution\n",
        "    filter = np.zeros((d, h, w), np.float64)\n",
        "    for i in range(d):\n",
        "        for j in range(h):\n",
        "            for k in range(w):\n",
        "                filter[i,j,k] = np.sqrt(np.exp(d))\n",
        "    return tf.convert_to_tensor(filter, dtype=tf.int32)\n",
        "\n",
        "# define a (stride-less) function for the convolution operation\n",
        "def conv_3D_oneshot(z, name=\"custom_conv_3D_1\"):\n",
        "    shape = z.get_shape().as_list()\n",
        "    depth = shape[0].value\n",
        "    height = shape[1].value\n",
        "    width = shape[2].value\n",
        "    filter = filter_1(depth, height, width)\n",
        "    return tf.math.reduce_sum(tf.math.multiply(z, filter), 0)'''"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# using a convolution operation (with a custom filter), conv_3D, for hidden layer h_2\\n\\n# define a custom filter, filter_1, to be used with the one-shot (stride-less) convolution operation, conv_3D_oneshot\\n#     ignoring padding for now\\ndef filter_1(d, h, w):\\n    # the latest sequence gets the highest contribution\\n    filter = np.zeros((d, h, w), np.float64)\\n    for i in range(d):\\n        for j in range(h):\\n            for k in range(w):\\n                filter[i,j,k] = np.sqrt(np.exp(d))\\n    return tf.convert_to_tensor(filter, dtype=tf.int32)\\n\\n# define a (stride-less) function for the convolution operation\\ndef conv_3D_oneshot(z, name=\"custom_conv_3D_1\"):\\n    shape = z.get_shape().as_list()\\n    depth = shape[0].value\\n    height = shape[1].value\\n    width = shape[2].value\\n    filter = filter_1(depth, height, width)\\n    return tf.math.reduce_sum(tf.math.multiply(z, filter), 0)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8sLsw1_jcKf",
        "colab_type": "text"
      },
      "source": [
        "Define architectural (hyper-)parameters..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yritMjt8pX2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define layers with #(nodes/layer), n_units_i, connected by weight matrices, w_i, and bias matrices, b_i\n",
        "\n",
        "n_inp_n = seq_series_data[0,:-1,:,:].shape[0]   # no. of 2x2 matrices fed as input (\"units\" per INPUT layer)\n",
        "n_units_1 = 4   # no. of units in the first hidden layer\n",
        "n_units_1_conv = n_units_1\n",
        "            # no. of (convolution) units in the output layer; must equal the number of units in the immediately preceding hidden layer\n",
        "n_outp_n  = seq_series_data_pred[:1,:,:].shape[0]\n",
        "            # number of (2x2) tensors the model must output (the same size as the sequence-size of the model output, 1 in the current case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VixpV7-4NS-j",
        "colab_type": "text"
      },
      "source": [
        "Build the layers..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WnwI7ofJtZR",
        "colab_type": "code",
        "outputId": "2ed02309-a67b-451b-e6e9-504ec2fcfb3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "with tf.name_scope(\"ann_1\"):    # test ANN model, \"ann_1\"\n",
        "    h_1 = tf.layers.dense(X, n_units_1, activation=softplus, use_bias=False, name=\"hidden_layer_1\")    # first hidden layer (linear activation)\n",
        "    f_1 = tf.get_variable(\"inp_to_outp_1\", [n_outp_n, n_inp_n], trainable=True, dtype=tf.float64)    # \"filter\" with zero strides, for \"one-shot convolution\"\n",
        "    hf_1 = tf.tensordot(f_1, h_1, axes = 1, name=\"hidden_funnel_layer_1\")   # funneling layer, to reduce input dimensions to output dimensions \n",
        "    h_2 = tf.layers.dense(hf_1, n_outp_n, activation=None,use_bias=False, name=\"output_layer\")    # output layer\n",
        "    Y_pred = tf.squeeze(h_2, [3])    # model output"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-d859a652c20f>:2: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS2SKRLHelL_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fb6595e3-39a3-444c-caf9-7a01e8b59e0f"
      },
      "source": [
        "Y_pred.get_shape()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(1), Dimension(2), Dimension(2)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O5JuU9wQbFm",
        "colab_type": "text"
      },
      "source": [
        "Define the loss function..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dTnlBToaItF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "64709f30-b6b0-40e2-e1eb-1b4b6be3eea5"
      },
      "source": [
        "with tf.name_scope(\"loss_ann_1\"):   # loss function for the model \"ann_1\"\n",
        "    accuracy = tf.losses.mean_squared_error(Y_pred, Y_true)   # element-wise MSE\n",
        "    loss = tf.math.reduce_mean(accuracy)    # the mean of the elements of the MSE tensor, computed above as \"accuracy\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r45-ABOPkqfh",
        "colab_type": "text"
      },
      "source": [
        "Choose the optimization algorithm to be used..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaIWZbSrvdfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn_rate = 0.1    # hyper-parameter for updating a variable v: v_new = v_old + delta_v = v_old - learn_rate*grad_v(loss)\n",
        "\n",
        "with tf.name_scope(\"opt_ann_1\"):    # optimizer for \"ann_1\"\n",
        "    opt = tf.train.GradientDescentOptimizer(learn_rate)   # use the gradient descent optimization algorithm\n",
        "    loss_min = opt.minimize(loss)   # operation to minimize \"loss\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG0nhyHtcD0B",
        "colab_type": "text"
      },
      "source": [
        "Set up initializer and session-saver objects (required for assigning initial values to the ```tf.Graph``` variables and saving the values of variables optimized in the session)..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fAiY8oRcET1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()    # initialize the model variables\n",
        "saver = tf.train.Saver()    # saves the updated parameters from a session run"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CltqEejDeG8",
        "colab_type": "text"
      },
      "source": [
        "**Running the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1k4UHmlCMoF",
        "colab_type": "text"
      },
      "source": [
        "Assigning no. of training cycles, batch-sizes, etc. ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DasD2I-1CQVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epoch = 100   # number of optimization steps on the WHOLE training dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2ZCOTsCB_w1",
        "colab_type": "text"
      },
      "source": [
        "Use a context manager to run the ```tf.Session```..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO4BdO_CB1am",
        "colab_type": "code",
        "outputId": "7c20ddee-cc69-42ca-c935-f66a4d9d64de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for train_epoch in range(n_epoch):\n",
        "        for batch_iter in range(seq_series_data.shape[0]):\n",
        "            inp = seq_series_data[batch_iter,:-1,:,:]\n",
        "            out = np.broadcast_to(seq_series_data_pred[batch_iter,:,:], [1, 2, 2])\n",
        "            sess.run(loss_min, feed_dict={X: inp, Y_true: out})\n",
        "        if (train_epoch % 5 == 0):\n",
        "            acc_train = accuracy.eval(feed_dict={X: inp, Y_true: out})\n",
        "            print(train_epoch, \"Batch accuracy (training):\", acc_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-f15d65720004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_series_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_series_data_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_true\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_epoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0macc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_true\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1157\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (3, 2, 2) for Tensor 'ExpandDims:0', which has shape '(?, 2, 2, 1)'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNDj8-SUjRMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}